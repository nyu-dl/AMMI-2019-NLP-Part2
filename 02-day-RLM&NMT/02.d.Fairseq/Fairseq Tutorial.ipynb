{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAIRSEQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from https://fairseq.readthedocs.io/en/latest/getting_started.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Fairseq(-py) is a sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling and other text generation tasks.\" It provides reference implementations of various sequence-to-sequence models making our life much more easier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install fairseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading some data and required scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! bash data/prepare-wmt14en2fr.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first see how to evaluate a pretrained model in fairseq. We'll download a pretrained model along with it's vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl https://dl.fbaipublicfiles.com/fairseq/models/wmt14.v2.en-fr.fconv-py.tar.bz2 | tar xvjf -"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This model uses a Byte Pair Encoding (BPE) vocabulary, so we’ll have to apply the encoding to the source text before it can be translated. This can be done with the apply_bpe.py script using the wmt14.en-fr.fconv-cuda/bpecodes file. @@ is used as a continuation marker and the original text can be easily recovered with e.g. sed s/@@ //g or by passing the --remove-bpe flag to fairseq-generate. Prior to BPE, input text needs to be tokenized using tokenizer.perl from mosesdecoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have written a script to do it, but as a fun example, let's do it in Jupyter Notebook for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Why is it rare to discover new marine mammal species ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$sentence\"\n",
    "SCRIPTS=data/mosesdecoder/scripts\n",
    "TOKENIZER=$SCRIPTS/tokenizer/tokenizer.perl\n",
    "CLEAN=$SCRIPTS/training/clean-corpus-n.perl\n",
    "NORM_PUNC=$SCRIPTS/tokenizer/normalize-punctuation.perl\n",
    "REM_NON_PRINT_CHAR=$SCRIPTS/tokenizer/remove-non-printing-char.perl\n",
    "BPEROOT=data/subword-nmt\n",
    "BPE_TOKENS=40000\n",
    "src=en\n",
    "tgt=fr\n",
    "echo $1 | \\\n",
    "            perl $NORM_PUNC $src | \\\n",
    "            perl $REM_NON_PRINT_CHAR | \\\n",
    "            perl $TOKENIZER -threads 8 -a -l $src > temp_tokenized.out         \n",
    "prep=wmt14.en-fr.fconv-py\n",
    "BPE_CODE=$prep/bpecodes\n",
    "python $BPEROOT/apply_bpe.py -c $BPE_CODE < temp_tokenized.out > final_result.out\n",
    "rm temp_tokenized.out\n",
    "cat final_result.out\n",
    "rm final_result.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the very cool interactive feature of fairseq. Open shell, cd to this directory and type the copy the following command:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MODEL_DIR=wmt14.en-fr.fconv-py\n",
    "fairseq-interactive \\\n",
    "    --path $MODEL_DIR/model.pt $MODEL_DIR \\\n",
    "    --beam 1 --source-lang en --target-lang fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "MODEL_DIR=wmt14.en-fr.fconv-py\n",
    "echo \"Why is it rare to discover new marine mam@@ mal species ?\" | fairseq-interactive \\\n",
    "    --path $MODEL_DIR/model.pt $MODEL_DIR \\\n",
    "    --beam 1 --source-lang en --target-lang fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generation script produces three types of outputs: a line prefixed with O is a copy of the original source sentence; H is the hypothesis along with an average log-likelihood; and P is the positional score per token position, including the end-of-sentence marker which is omitted from the text. Let's do this in bash again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!  echo \"Why is it rare to discover new marine mam@@ mal species ?\" | sed -r 's/(@@ )|(@@ ?$)//g' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Good! Now let's train a new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fairseq contains example pre-processing scripts for several translation datasets: IWSLT 2014 (German-English), WMT 2014 (English-French) and WMT 2014 (English-German). We will work with a part of WMT 2014 like we did in the previous section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To pre-process and binarize the IWSLT dataset run <code>bash prepare-wmt14en2fr.sh</code> like we did for the previous section. This will download the data, tokenize it, perform byte pair encoding and do a test train split on the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Binaize the data, we do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "TEXT=data/wmt14_en_fr\n",
    "fairseq-preprocess --source-lang en --target-lang fr \\\n",
    "  --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test \\\n",
    "  --destdir data-bin/wmt14_en_fr --thresholdtgt 5 --thresholdsrc 5 \\\n",
    "  --workers 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ofcourse, we cannot see what is inside the binary line, but let's check what is in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls data-bin/wmt14_en_fr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -5 data-bin/wmt14_en_fr/dict.en.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -5 data-bin/wmt14_en_fr/dict.fr.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fairseq provides a lot of predefined architectures to choose from. For English-French, we will choose an architecure known to work well for the problem. In the next section, we will see how to define custom models in Fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p fairseq_models/checkpoints/fconv_wmt_en_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! fairseq-train data-bin/wmt14_en_fr \\\n",
    "  --lr 0.5 --clip-norm 0.1 --dropout 0.1 --max-tokens 3000 \\\n",
    "  --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "  --lr-scheduler fixed --force-anneal 50 \\\n",
    "  --arch fconv_wmt_en_fr --save-dir fairseq_models/checkpoints/fconv_wmt_en_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls data-bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating and Checking BLEU for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p fairseq_models/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "fairseq-generate data-bin/wmt14_en_fr  \\\n",
    "  --path fairseq_models/checkpoints/fconv_wmt_en_fr/checkpoint_best.pt \\\n",
    "  --beam 1 --batch-size 128 --remove-bpe --sacrebleu  >> fairseq_models/logs/our_model.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -10 fairseq_models/logs/our_model.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail -2 fairseq_models/logs/our_model.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating and Checking BLEU for the large Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl https://dl.fbaipublicfiles.com/fairseq/data/wmt14.v2.en-fr.newstest2014.tar.bz2 | tar xvjf - -C data-bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "fairseq-generate data-bin/wmt14.en-fr.newstest2014  \\\n",
    "  --path wmt14.en-fr.fconv-py/model.pt \\\n",
    "  --beam 1 --batch-size 128 --remove-bpe --sacrebleu >> fairseq_models/logs/pretrained_model.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -10 fairseq_models/logs/pretrained_model.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tail -2 fairseq_models/logs/pretrained_model.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing A Custom Model in FAIRSEQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will extend fairseq by adding a new FairseqModel that encodes a source sentence with an LSTM and then passes the final hidden state to a second LSTM that decodes the target sentence (without attention)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an Encoder and Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we’ll define a simple LSTM Encoder and Decoder. All Encoders should implement the FairseqEncoder interface and Decoders should implement the FairseqDecoder interface. These interfaces themselves extend torch.nn.Module, so FairseqEncoders and FairseqDecoders can be written and used in the same ways as ordinary PyTorch Modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Encoder will embed the tokens in the source sentence, feed them to a torch.nn.LSTM and return the final hidden state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Decoder will predict the next word, conditioned on the Encoder’s final hidden state and an embedded representation of the previous target word – which is sometimes called input feeding or teacher forcing. More specifically, we’ll use a torch.nn.LSTM to produce a sequence of hidden states that we’ll project to the size of the output vocabulary to predict each target word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we’ve defined our Encoder and Decoder we must register our model with fairseq using the register_model() function decorator. Once the model is registered we’ll be able to use it with the existing Command-line Tools.\n",
    "\n",
    "All registered models must implement the BaseFairseqModel interface. For sequence-to-sequence models (i.e., any model with a single Encoder and Decoder), we can instead implement the FairseqModel interface.\n",
    "\n",
    "Create a small wrapper class in the same file and register it in fairseq with the name 'simple_lstm':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let’s define a named architecture with the configuration for our model. This is done with the register_model_architecture() function decorator. Thereafter this named architecture can be used with the --arch command-line argument, e.g., --arch tutorial_simple_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/sm7582/condaenvs/denoising/lib/python3.7/site-packages/fairseq/models\n"
     ]
    }
   ],
   "source": [
    "import fairseq\n",
    "import os\n",
    "fairseq_path = os.path.dirname(fairseq.__file__)\n",
    "fairseq_path = os.path.join(fairseq_path, 'models')\n",
    "print(fairseq_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$fairseq_path\"\n",
    "cp fairseq_models/custom_models/simple_lstm.py $1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$fairseq_path\"\n",
    "ls $1 | grep lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Our Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p fairseq_models/checkpoints/tutorial_simple_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(adam_betas='(0.9, 0.999)', adam_eps=1e-08, arch='tutorial_simple_lstm', bucket_cap_mb=25, clip_norm=25, cpu=False, criterion='cross_entropy', data=['data-bin/wmt14_en_fr'], ddp_backend='c10d', decoder_dropout=0.2, decoder_embed_dim=256, decoder_hidden_dim=256, device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, distributed_rank=0, distributed_world_size=1, encoder_dropout=0.2, encoder_embed_dim=256, encoder_hidden_dim=256, fix_batches_to_gpus=False, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, lazy_load=False, left_pad_source='True', left_pad_target='False', log_format=None, log_interval=1000, lr=[0.005], lr_scheduler='reduce_lr_on_plateau', lr_shrink=0.5, max_epoch=50, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=12000, max_update=0, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-05, momentum=0.99, no_epoch_checkpoints=False, no_progress_bar=False, no_save=False, num_workers=0, optimizer='adam', optimizer_overrides='{}', raw_text=False, reset_lr_scheduler=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='fairseq_models/checkpoints/tutorial_simple_lstm', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation', train_subset='train', update_freq=[1], upsample_primary=1, user_dir=None, valid_subset='valid', validate_interval=1, weight_decay=0.0)\n",
      "| [en] dictionary: 21720 types\n",
      "| [fr] dictionary: 24256 types\n",
      "| data-bin/wmt14_en_fr train 166769 examples\n",
      "| data-bin/wmt14_en_fr valid 1359 examples\n",
      "SimpleLSTMModel(\n",
      "  (encoder): SimpleLSTMEncoder(\n",
      "    (embed_tokens): Embedding(21720, 256, padding_idx=1)\n",
      "    (dropout): Dropout(p=0.2)\n",
      "    (lstm): LSTM(256, 256)\n",
      "  )\n",
      "  (decoder): SimpleLSTMDecoder(\n",
      "    (embed_tokens): Embedding(24256, 256, padding_idx=1)\n",
      "    (dropout): Dropout(p=0.2)\n",
      "    (lstm): LSTM(512, 256)\n",
      "    (output_projection): Linear(in_features=256, out_features=24256, bias=True)\n",
      "  )\n",
      ")\n",
      "SimpleLSTMModel(\n",
      "  (encoder): SimpleLSTMEncoder(\n",
      "    (embed_tokens): Embedding(21720, 256, padding_idx=1)\n",
      "    (dropout): Dropout(p=0.2)\n",
      "    (lstm): LSTM(256, 256)\n",
      "  )\n",
      "  (decoder): SimpleLSTMDecoder(\n",
      "    (embed_tokens): Embedding(24256, 256, padding_idx=1)\n",
      "    (dropout): Dropout(p=0.2)\n",
      "    (lstm): LSTM(512, 256)\n",
      "    (output_projection): Linear(in_features=256, out_features=24256, bias=True)\n",
      "  )\n",
      ")\n",
      "| model tutorial_simple_lstm, criterion CrossEntropyCriterion\n",
      "| num. model params: 19318464 (num. trained: 19318464)\n",
      "| training on 1 GPUs\n",
      "| max tokens per GPU = 12000 and max sentences per GPU = None\n",
      "| no existing checkpoint found fairseq_models/checkpoints/tutorial_simple_lstm/checkpoint_last.pt\n",
      "| epoch 001 | loss 7.857 | ppl 231.86 | wps 70535 | ups 6.1 | wpb 11144 | bsz 338 | num_updates 493 | lr 0.005 | gnorm 0.303 | clip 0% | oom 0 | wall 80 | train_wall 62\n",
      "| epoch 001 | valid on 'valid' subset | valid_loss 7.00393 | valid_ppl 128.35 | num_updates 493\n",
      "| epoch 002 | loss 6.815 | ppl 112.62 | wps 70565 | ups 6.1 | wpb 11144 | bsz 338 | num_updates 986 | lr 0.005 | gnorm 0.175 | clip 0% | oom 0 | wall 161 | train_wall 124\n",
      "| epoch 002 | valid on 'valid' subset | valid_loss 6.61833 | valid_ppl 98.25 | num_updates 986 | best 6.61833\n",
      "| epoch 003 | loss 6.504 | ppl 90.74 | wps 70745 | ups 6.0 | wpb 11144 | bsz 338 | num_updates 1479 | lr 0.005 | gnorm 0.160 | clip 0% | oom 0 | wall 243 | train_wall 185\n",
      "| epoch 003 | valid on 'valid' subset | valid_loss 6.40896 | valid_ppl 84.97 | num_updates 1479 | best 6.40896\n",
      "| epoch 004 | loss 6.248 | ppl 76.03 | wps 70815 | ups 6.0 | wpb 11144 | bsz 338 | num_updates 1972 | lr 0.005 | gnorm 0.142 | clip 0% | oom 0 | wall 325 | train_wall 247\n",
      "| epoch 004 | valid on 'valid' subset | valid_loss 6.21648 | valid_ppl 74.36 | num_updates 1972 | best 6.21648\n",
      "| epoch 005 | loss 6.031 | ppl 65.40 | wps 70599 | ups 6.0 | wpb 11144 | bsz 338 | num_updates 2465 | lr 0.005 | gnorm 0.129 | clip 0% | oom 0 | wall 407 | train_wall 308\n",
      "| epoch 005 | valid on 'valid' subset | valid_loss 6.07697 | valid_ppl 67.51 | num_updates 2465 | best 6.07697\n",
      "| epoch 006 | loss 5.858 | ppl 58.00 | wps 70344 | ups 6.0 | wpb 11144 | bsz 338 | num_updates 2958 | lr 0.005 | gnorm 0.120 | clip 0% | oom 0 | wall 490 | train_wall 370\n",
      "| epoch 006 | valid on 'valid' subset | valid_loss 5.98528 | valid_ppl 63.35 | num_updates 2958 | best 5.98528\n",
      "| epoch 007 | loss 5.724 | ppl 52.87 | wps 70138 | ups 5.9 | wpb 11144 | bsz 338 | num_updates 3451 | lr 0.005 | gnorm 0.120 | clip 0% | oom 0 | wall 573 | train_wall 432\n",
      "| epoch 007 | valid on 'valid' subset | valid_loss 5.92019 | valid_ppl 60.56 | num_updates 3451 | best 5.92019\n",
      "| epoch 008 | loss 5.610 | ppl 48.85 | wps 70181 | ups 6.0 | wpb 11144 | bsz 338 | num_updates 3944 | lr 0.005 | gnorm 0.122 | clip 0% | oom 0 | wall 655 | train_wall 494\n",
      "| epoch 008 | valid on 'valid' subset | valid_loss 5.87026 | valid_ppl 58.50 | num_updates 3944 | best 5.87026\n",
      "| epoch 009 | loss 5.510 | ppl 45.56 | wps 70177 | ups 6.0 | wpb 11144 | bsz 338 | num_updates 4437 | lr 0.005 | gnorm 0.121 | clip 0% | oom 0 | wall 737 | train_wall 555\n",
      "| epoch 009 | valid on 'valid' subset | valid_loss 5.82237 | valid_ppl 56.59 | num_updates 4437 | best 5.82237\n",
      "| epoch 010 | loss 5.422 | ppl 42.87 | wps 70510 | ups 5.9 | wpb 11144 | bsz 338 | num_updates 4930 | lr 0.005 | gnorm 0.125 | clip 0% | oom 0 | wall 821 | train_wall 617\n",
      "| epoch 010 | valid on 'valid' subset | valid_loss 5.78576 | valid_ppl 55.17 | num_updates 4930 | best 5.78576\n",
      "| epoch 011 | loss 5.343 | ppl 40.58 | wps 70471 | ups 5.6 | wpb 11144 | bsz 338 | num_updates 5423 | lr 0.005 | gnorm 0.122 | clip 0% | oom 0 | wall 909 | train_wall 679\n",
      "| epoch 011 | valid on 'valid' subset | valid_loss 5.76272 | valid_ppl 54.29 | num_updates 5423 | best 5.76272\n",
      "| epoch 012 | loss 5.278 | ppl 38.80 | wps 70520 | ups 5.4 | wpb 11144 | bsz 338 | num_updates 5916 | lr 0.005 | gnorm 0.128 | clip 0% | oom 0 | wall 1000 | train_wall 740\n",
      "| epoch 012 | valid on 'valid' subset | valid_loss 5.76127 | valid_ppl 54.24 | num_updates 5916 | best 5.76127\n",
      "| epoch 013 | loss 5.217 | ppl 37.19 | wps 70437 | ups 4.9 | wpb 11144 | bsz 338 | num_updates 6409 | lr 0.005 | gnorm 0.126 | clip 0% | oom 0 | wall 1102 | train_wall 802\n",
      "| epoch 013 | valid on 'valid' subset | valid_loss 5.7585 | valid_ppl 54.14 | num_updates 6409 | best 5.7585\n",
      "| epoch 014 | loss 5.164 | ppl 35.86 | wps 70432 | ups 6.0 | wpb 11144 | bsz 338 | num_updates 6902 | lr 0.005 | gnorm 0.131 | clip 0% | oom 0 | wall 1184 | train_wall 863\n",
      "| epoch 014 | valid on 'valid' subset | valid_loss 5.73661 | valid_ppl 53.32 | num_updates 6902 | best 5.73661\n",
      "| epoch 015 | loss 5.114 | ppl 34.62 | wps 70425 | ups 6.0 | wpb 11144 | bsz 338 | num_updates 7395 | lr 0.005 | gnorm 0.130 | clip 0% | oom 0 | wall 1266 | train_wall 925\n",
      "| epoch 015 | valid on 'valid' subset | valid_loss 5.74731 | valid_ppl 53.72 | num_updates 7395 | best 5.73661\n",
      "| epoch 016 | loss 4.970 | ppl 31.35 | wps 70478 | ups 6.1 | wpb 11144 | bsz 338 | num_updates 7888 | lr 0.0025 | gnorm 0.126 | clip 0% | oom 0 | wall 1346 | train_wall 987\n",
      "| epoch 016 | valid on 'valid' subset | valid_loss 5.6901 | valid_ppl 51.63 | num_updates 7888 | best 5.6901\n",
      "| epoch 017 | loss 4.931 | ppl 30.50 | wps 70421 | ups 6.0 | wpb 11144 | bsz 338 | num_updates 8381 | lr 0.0025 | gnorm 0.130 | clip 0% | oom 0 | wall 1428 | train_wall 1048\n",
      "| epoch 017 | valid on 'valid' subset | valid_loss 5.68519 | valid_ppl 51.45 | num_updates 8381 | best 5.68519\n",
      "| epoch 018 | loss 4.901 | ppl 29.87 | wps 70401 | ups 6.0 | wpb 11144 | bsz 338 | num_updates 8874 | lr 0.0025 | gnorm 0.132 | clip 0% | oom 0 | wall 1510 | train_wall 1110\n",
      "| epoch 018 | valid on 'valid' subset | valid_loss 5.6775 | valid_ppl 51.18 | num_updates 8874 | best 5.6775\n",
      "| epoch 019 | loss 4.875 | ppl 29.34 | wps 70238 | ups 5.9 | wpb 11144 | bsz 338 | num_updates 9367 | lr 0.0025 | gnorm 0.134 | clip 0% | oom 0 | wall 1593 | train_wall 1172\n",
      "| epoch 019 | valid on 'valid' subset | valid_loss 5.6751 | valid_ppl 51.09 | num_updates 9367 | best 5.6751\n",
      "| epoch 020 | loss 4.850 | ppl 28.85 | wps 70249 | ups 6.1 | wpb 11144 | bsz 338 | num_updates 9860 | lr 0.0025 | gnorm 0.139 | clip 0% | oom 0 | wall 1674 | train_wall 1234\n",
      "| epoch 020 | valid on 'valid' subset | valid_loss 5.67606 | valid_ppl 51.13 | num_updates 9860 | best 5.6751\n",
      "| epoch 021 | loss 4.776 | ppl 27.39 | wps 70246 | ups 6.0 | wpb 11144 | bsz 338 | num_updates 10353 | lr 0.00125 | gnorm 0.135 | clip 0% | oom 0 | wall 1756 | train_wall 1296\n",
      "| epoch 021 | valid on 'valid' subset | valid_loss 5.65424 | valid_ppl 50.36 | num_updates 10353 | best 5.65424\n",
      "| epoch 022 | loss 4.755 | ppl 27.01 | wps 70264 | ups 5.9 | wpb 11144 | bsz 338 | num_updates 10846 | lr 0.00125 | gnorm 0.135 | clip 0% | oom 0 | wall 1839 | train_wall 1357\n",
      "| epoch 022 | valid on 'valid' subset | valid_loss 5.65619 | valid_ppl 50.43 | num_updates 10846 | best 5.65424\n",
      "| epoch 023 | loss 4.717 | ppl 26.30 | wps 70237 | ups 6.1 | wpb 11144 | bsz 338 | num_updates 11339 | lr 0.000625 | gnorm 0.133 | clip 0% | oom 0 | wall 1920 | train_wall 1419\n",
      "| epoch 023 | valid on 'valid' subset | valid_loss 5.6421 | valid_ppl 49.94 | num_updates 11339 | best 5.6421\n",
      "| epoch 024 | loss 4.706 | ppl 26.10 | wps 70318 | ups 5.9 | wpb 11144 | bsz 338 | num_updates 11832 | lr 0.000625 | gnorm 0.136 | clip 0% | oom 0 | wall 2003 | train_wall 1481\n",
      "| epoch 024 | valid on 'valid' subset | valid_loss 5.64406 | valid_ppl 50.01 | num_updates 11832 | best 5.6421\n",
      "| epoch 025 | loss 4.685 | ppl 25.73 | wps 70522 | ups 6.1 | wpb 11144 | bsz 338 | num_updates 12325 | lr 0.0003125 | gnorm 0.132 | clip 0% | oom 0 | wall 2084 | train_wall 1543\n",
      "| epoch 025 | valid on 'valid' subset | valid_loss 5.64128 | valid_ppl 49.91 | num_updates 12325 | best 5.64128\n",
      "| epoch 026 | loss 4.681 | ppl 25.65 | wps 70528 | ups 5.9 | wpb 11144 | bsz 338 | num_updates 12818 | lr 0.0003125 | gnorm 0.130 | clip 0% | oom 0 | wall 2168 | train_wall 1605\n",
      "| epoch 026 | valid on 'valid' subset | valid_loss 5.64178 | valid_ppl 49.93 | num_updates 12818 | best 5.64128\n",
      "| epoch 027 | loss 4.669 | ppl 25.44 | wps 70548 | ups 6.1 | wpb 11144 | bsz 338 | num_updates 13311 | lr 0.00015625 | gnorm 0.132 | clip 0% | oom 0 | wall 2249 | train_wall 1667\n",
      "| epoch 027 | valid on 'valid' subset | valid_loss 5.64005 | valid_ppl 49.87 | num_updates 13311 | best 5.64005\n",
      "| epoch 028 | loss 4.666 | ppl 25.39 | wps 70567 | ups 6.0 | wpb 11144 | bsz 338 | num_updates 13804 | lr 0.00015625 | gnorm 0.132 | clip 0% | oom 0 | wall 2331 | train_wall 1729\n",
      "| epoch 028 | valid on 'valid' subset | valid_loss 5.63895 | valid_ppl 49.83 | num_updates 13804 | best 5.63895\n",
      "| epoch 029 | loss 4.665 | ppl 25.36 | wps 70574 | ups 6.0 | wpb 11144 | bsz 338 | num_updates 14297 | lr 0.00015625 | gnorm 0.132 | clip 0% | oom 0 | wall 2413 | train_wall 1790\n",
      "| epoch 029 | valid on 'valid' subset | valid_loss 5.63815 | valid_ppl 49.80 | num_updates 14297 | best 5.63815\n",
      "| epoch 030 | loss 4.662 | ppl 25.32 | wps 70704 | ups 5.0 | wpb 11144 | bsz 338 | num_updates 14790 | lr 0.00015625 | gnorm 0.134 | clip 0% | oom 0 | wall 2513 | train_wall 1852\n",
      "| epoch 030 | valid on 'valid' subset | valid_loss 5.63902 | valid_ppl 49.83 | num_updates 14790 | best 5.63815\n",
      "| epoch 031 | loss 4.657 | ppl 25.23 | wps 70662 | ups 6.1 | wpb 11144 | bsz 338 | num_updates 15283 | lr 7.8125e-05 | gnorm 0.132 | clip 0% | oom 0 | wall 2594 | train_wall 1914\n",
      "| epoch 031 | valid on 'valid' subset | valid_loss 5.6389 | valid_ppl 49.83 | num_updates 15283 | best 5.63815\n",
      "| epoch 032 | loss 4.654 | ppl 25.17 | wps 70686 | ups 6.1 | wpb 11144 | bsz 338 | num_updates 15776 | lr 3.90625e-05 | gnorm 0.132 | clip 0% | oom 0 | wall 2674 | train_wall 1975\n",
      "| epoch 032 | valid on 'valid' subset | valid_loss 5.63818 | valid_ppl 49.80 | num_updates 15776 | best 5.63815\n",
      "| epoch 033 | loss 4.652 | ppl 25.14 | wps 70576 | ups 6.1 | wpb 11144 | bsz 338 | num_updates 16269 | lr 1.95313e-05 | gnorm 0.131 | clip 0% | oom 0 | wall 2755 | train_wall 2037\n",
      "| epoch 033 | valid on 'valid' subset | valid_loss 5.63808 | valid_ppl 49.80 | num_updates 16269 | best 5.63808\n",
      "| done training in 2758.2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sm7582/condaenvs/denoising/lib/python3.7/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "fairseq-train data-bin/wmt14_en_fr \\\n",
    "  --arch tutorial_simple_lstm \\\n",
    "  --encoder-dropout 0.2 --decoder-dropout 0.2 \\\n",
    "  --optimizer adam --lr 0.005 --lr-shrink 0.5 \\\n",
    "  --max-epoch 50 \\\n",
    "  --max-tokens 12000 --save-dir fairseq_models/checkpoints/tutorial_simple_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "fairseq-generate data-bin/wmt14_en_fr  \\\n",
    "  --path fairseq_models/checkpoints/tutorial_simple_lstm/checkpoint_best.pt \\\n",
    "  --beam 1 --batch-size 128 --remove-bpe --sacrebleu  >> fairseq_models/logs/custom_model.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(beam=1, cpu=False, data=['data-bin/wmt14_en_fr'], diverse_beam_groups=-1, diverse_beam_strength=0.5, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', lazy_load=False, left_pad_source='True', left_pad_target='False', lenpen=1, log_format=None, log_interval=1000, match_source_len=False, max_len_a=0, max_len_b=200, max_sentences=128, max_source_positions=1024, max_target_positions=1024, max_tokens=None, memory_efficient_fp16=False, min_len=1, model_overrides='{}', nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, num_shards=1, num_workers=0, path='fairseq_models/checkpoints/tutorial_simple_lstm/checkpoint_best.pt', prefix_size=0, print_alignment=False, quiet=False, raw_text=False, remove_bpe='@@ ', replace_unk=None, sacrebleu=True, sampling=False, sampling_temperature=1, sampling_topk=-1, score_reference=False, seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation', unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None)\n",
      "| [en] dictionary: 21720 types\n",
      "| [fr] dictionary: 24256 types\n",
      "| data-bin/wmt14_en_fr test 3003 examples\n",
      "| ['data-bin/wmt14_en_fr'] test 3003 examples\n",
      "| loading model(s) from fairseq_models/checkpoints/tutorial_simple_lstm/checkpoint_best.pt\n",
      "SimpleLSTMModel(\n",
      "  (encoder): SimpleLSTMEncoder(\n",
      "    (embed_tokens): Embedding(21720, 256, padding_idx=1)\n",
      "    (dropout): Dropout(p=0.2)\n"
     ]
    }
   ],
   "source": [
    "!head -10 fairseq_models/logs/custom_model.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Translated 3003 sentences (95826 tokens) in 17.3s (173.62 sentences/s, 5540.33 tokens/s)\n",
      "| Generate test with beam=1: BLEU(score=2.920992351091757, counts=[20940, 3724, 1489, 594], totals=[97757, 94754, 91752, 88750], precisions=[21.4204609388586, 3.9301770901492286, 1.6228529078385212, 0.6692957746478874], bp=0.9445955091061184, sys_len=97757, ref_len=103329)\n"
     ]
    }
   ],
   "source": [
    "!tail -2 fairseq_models/logs/custom_model.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
